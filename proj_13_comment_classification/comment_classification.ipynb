{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "The goal of this project was to train a model that will classify comments as either toxic or non-toxic for moderation purposes.\n",
    "\n",
    "The dataset includes the text of comments as well as their labels (i.e. toxic or not). The metric used to evaluate the final model was F1 score.\n",
    "\n",
    "This task could have been approached in a variety of ways, but I decided to train a neural network using BERT to achieve the final goal. As I am new to working with neural networks, I attempted to explain the purpose of different steps in an effort to understand them better myself. Furthermore, I was unsuccessful in my first attempt to train a network, but I decided to leave the code from the first attempt at the bottom of this project.\n",
    "\n",
    "*Note: Like with other projects, much of the code is commented to avoid rerunning code unnecessarily during later edits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Импорты\" data-toc-modified-id=\"Импорты-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Импорты</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Подготовка-BERTа\" data-toc-modified-id=\"Подготовка-BERTа-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Подготовка BERTа</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Подготовка данных</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-sklearn-моделей\" data-toc-modified-id=\"Проверка-sklearn-моделей-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Проверка sklearn моделей</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#XGBClassifier\" data-toc-modified-id=\"XGBClassifier-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>XGBClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#Лучшие-модели\" data-toc-modified-id=\"Лучшие-модели-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Лучшие модели</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Первая-попытка\" data-toc-modified-id=\"Первая-попытка\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Первая попытка</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import optuna\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from pytorch_transformers import BertConfig, DistilBertConfig\n",
    "import transformers\n",
    "from transformers import BertModel, DistilBertModel\n",
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Classifiers\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    comments = pd.read_csv(\"datasets/toxic_comments.csv\")\n",
    "    \n",
    "except:\n",
    "    comments = pd.read_csv(\"/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токсичных комментариев: 16225\n",
      "Количество не токсичных комментакиев: 143346\n",
      "Процент токсичных комментариев в выборка: 11.31876717871444\n"
     ]
    }
   ],
   "source": [
    "comments.info()\n",
    "display(comments.head())\n",
    "print(f'Количество токсичных комментариев: {len(comments.query(\"toxic == 1\"))}')\n",
    "print(f'Количество не токсичных комментакиев: {len(comments.query(\"toxic == 0\"))}')\n",
    "print(f'Процент токсичных комментариев в выборка: {len(comments.query(\"toxic == 1\"))/len(comments.query(\"toxic == 0\"))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([comm for comm in comments if r'[а-яА-Я]+' in comm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка и посмотр данных**\n",
    "\n",
    "Данные в хорошем состоянии, а их много (159571). Столбца только два – один с комментариями, а другой с оценкой токсичности. Пропусков нет. Все комментарии на английском.\n",
    "\n",
    "Однако, наблюдается значительный дисбаланс классов (примерно 1:9). Это может влиять на обучение и итоговое качество модели, поэтому нужно избавиться от такого дисбаланса. Это часто делается с помощью upsampling или downsampling, но из-за изначального размера этого датасета, логично делать downsampling (что в итоге уменьшит общее количество данных)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка BERTа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решил использовать BERT для этого проекта. Я использовал bert-base-uncased; это (сравнительно) маленькая версия BERTа, а она не учитывает регистра слов. Я не стал изменить ничего в модели, то есть использовал и предобученное BERT, и использовал стандартную конфигурацию.\n",
    "\n",
    "\n",
    "Из-за того, что я использовал BertTokenizer, не пришлось отдельно заниматься паддингом или маской."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я создал класс для данных. Это сделано для удобства; это способствовало эмбеддингу ниже, но и также было легче экспериментировать с данными и в них разобраться (по второй этой причине есть в классе столько ненужных для задачи методов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(comments, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токсичных комментариев после downsampling: 12064\n",
      "Количество не токсичных комментариев после downsampling: 12064\n"
     ]
    }
   ],
   "source": [
    "def downsample(df):\n",
    "    \n",
    "    fraction = len(df.query('toxic == 1'))/len(df.query('toxic == 0'))\n",
    "    \n",
    "    toxic = df[df['toxic'] == 1]\n",
    "    non_toxic = df[df['toxic'] == 0]\n",
    "    \n",
    "    downsampled = pd.concat([toxic] + [non_toxic.sample(frac=fraction, random_state=12345)])\n",
    "    \n",
    "    downsampled = shuffle(downsampled, random_state=12345)\n",
    "\n",
    "    return downsampled\n",
    "    \n",
    "train_downsampled = downsample(train)\n",
    "\n",
    "print(f'Количество токсичных комментариев после downsampling: {len(train_downsampled.query(\"toxic == 1\"))}')\n",
    "print(f'Количество не токсичных комментариев после downsampling: {len(train_downsampled.query(\"toxic == 0\"))}')\n",
    "\n",
    "index_check = list(train_downsampled.head(10).index)\n",
    "assert train['toxic'][index_check].values.all() == train_downsampled['toxic'][index_check].values.all()\n",
    "\n",
    "train = train_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество комментариев в train после downsampling: 24128\n",
      "Количество комментариев в test: 39893\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество комментариев в train после downsampling: {len(train)}')\n",
    "print(f'Количество комментариев в test: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "        ### max_token_len возможно, что это важно для определённых задач, но для этого проекта я использовал 512, то есть\n",
    "        ### максимум, что bert может\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        sent = data_row['text']\n",
    "        label = data_row['toxic'].flatten()\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "\n",
    "        )\n",
    "\n",
    "        \n",
    "        ### это не только возвращает данные но и применяет tokenizer \n",
    "        \n",
    "        \n",
    "        return dict(\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.tensor(label, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "train_dataset = SamplingDataset(train, bert_tokenizer, 64)\n",
    "val_dataset = SamplingDataset(test, bert_tokenizer, 64)\n",
    "\n",
    "\n",
    "bert_train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True,\n",
    "                              num_workers=0)\n",
    "\n",
    "bert_eval_dataloader = DataLoader(val_dataset, batch_size=16, num_workers=0)\n",
    "\n",
    "\n",
    "    ### DataLoader здесь принимает:\n",
    "\n",
    "    # данные в форме Dataset (поэтому использовано torch.utils.data.Dataset как база при выявлении класса SamplingDataset)\n",
    "\n",
    "    # batch_size > размер батча. Я читал, что чаще всего рекомендуют батчсайз 32. Тоже читал, что при меньших батчах, \n",
    "    # быстрее обрабатывается данные, но бывает, что тогда точность может пострадать.\n",
    "\n",
    "    # num_workers > если num_workers=0, тогда процесс передачы данных (data fetching) выпускается в том же процессе как\n",
    "    # и сам DataLoader. Из-за этого этот процесс может остановить общий процесс вычисления (вроде так, было \n",
    "    # написано \"may block computing\").\n",
    "    # Когда num_workers какое-нибудь положительное число, тогда создано столько процессов для параллелной обработки.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassBert(nn.Module):\n",
    "    def __init__(self, model_path=None, config=None, num_labels=2):\n",
    "        super(ClassBert, self).__init__() # super() даёт возможность использовать class (и их параметры) при создании других class-ов\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(model_path)\n",
    "        self.dropout = nn.Dropout(0.5) # dropout – переписывает часть тенсора нулями; здесь 0.5 > половина чисел в тенсоре будут переписаны как 0\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.linear2 = nn.Linear(256, self.num_labels)\n",
    "                                # 768 – hidden size самой модели bert-base, 2 – количество классов (toxic или non-toxic)\n",
    "                                # это подготавливает матрицы для того, чтобы работать с ними дальше (для forward propagation)\n",
    "                                # не понимаю, откуда берётся 256, но заметно, что 256 становится первым изменернием в Linear2\n",
    "        self.relu = nn.ReLU() # ReLu это функция для активации, которая делает сеть не-линейной.\n",
    "                                # Как я понимаю, слои линейные, но не хотим, чтобы сеть из них тоже получилась линейной, ReLU помогает с этим\n",
    "\n",
    "    def forward(self, input_ids, input_mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=input_mask, return_dict=False) #1\n",
    "\n",
    "        dropout_output = self.dropout(pooled_output) #2\n",
    "        linear_output = self.linear1(dropout_output) #3\n",
    "        final_layer = self.relu(linear_output) #4\n",
    "        final_layer = self.linear2(final_layer) #3 ещё раз?\n",
    "        return final_layer\n",
    "    \n",
    "    \n",
    "        ''' \n",
    "        1: преобразование данных в форму bert (transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)\n",
    "            - это работает с первым созданным классом Dataset\n",
    "                - от класса Dataset получаем input_id и attention_mask\n",
    "            - возвращает два torch.Tensor\n",
    "            \n",
    "        2: берёт эти тенсоры и применяет dropout, переписывая часть (здесь: половина) чисел в тенсоре в 0\n",
    "        \n",
    "        3: преобразует данные используя y = x(A^t) + b\n",
    "            - важно, что меняет размер последного измерение\n",
    "                - здесь, получится, что последное измерение (X в torch.size([a, X]) будет 2, поскольку это соответствует нашей задаче\n",
    "                \n",
    "            - преобразование final_layer\n",
    "                - это интересно, а этого не было в моей первой попытке для этого проекта\n",
    "                - видно, что у linear1 второе измерение 256, а у linear2 – 2\n",
    "                    - 2 (linear2) конечно соответствует нашей задаче (у нас две группы комментариев – токсичные и не токсичные)\n",
    "                    - 256 это - видимо это нужно, чтобы подготавливать данные к применению .relu\n",
    "                        \n",
    "        4: способствует работе сети для сложных задач, предотвращая линейной зависимости между слоями сети\n",
    "         '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = ClassBert(model_path='bert-base-uncased')\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\") \n",
    "\n",
    "learning_rate = 1e-05\n",
    "bert_optimizer = torch.optim.Adam(params=bert_model.parameters(), lr=learning_rate)\n",
    "# Adam это алгоритм для оптимтзации, тут lr влияет на то, насколько быстро/значительно меняется градиент ()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "bert_scheduler = torch.optim.lr_scheduler.StepLR(bert_optimizer, step_size=2, gamma=0.1)\n",
    "# это работает с bert_optimizer, меняя lr постепенно, с каждой эпохой\n",
    "n_epochs=4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=device):\n",
    "\n",
    "    model.to(device).train()\n",
    "    with tqdm(total=len(train_dataloader)) as pbar: #pbar это progress bar; рантьше я использовал tqdm с циклом, \n",
    "                                                   #  а pbar позволяет tqdm работать с len(train_dataloader) вместо цикла\n",
    "        for batch in train_dataloader:\n",
    "            # добавляем батч для вычисления на GPU\n",
    "            # Распаковываем данные из dataloader\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            # класс Dataset (здесь через DataLoader) как раз возвращает: input_ids, attention_mask, labels\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].view(-1).to(device)\n",
    "\n",
    "            optimizer.zero_grad() # это важно чтобы восстановмит значение градиента (чтобы значения от предыдущего батча не остались)\n",
    "            output = model.forward(input_ids, attention_mask)\n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # как я понимаю, loss.backward() и optimizer.step() чаще всего (всегда?) применяюься вместе, как раз в конце каждого\n",
    "            # такого цикла. Они связаны с работой criterion и optimizer, то есть именно с тем, как они работают внутри себя.\n",
    "            # .backward() вычисляет градиент, используя все предыдущие значения\n",
    "            # .step() обновляет значение, используемое в градиенте\n",
    "            \n",
    "            _, predicted = torch.max(output.detach(), 1)\n",
    "            f1 = f1_score(predicted.cpu().numpy(), labels.cpu().numpy(), zero_division=0)\n",
    "            pbar.set_description('Loss: {:.4f}; F1_score: {:.4f}'.format(loss.item(), f1))    \n",
    "            pbar.update(1)\n",
    "\n",
    "def predict(model, val_dataloader, criterion, device=device):\n",
    "    # в целом predict почти то же самое, как train_one_epoch\n",
    "    # главное отличие в том, что тут нет оптимизации/нет градиента\n",
    "    model.to(device).eval()\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    # эти будут содержать информацию (про losses (не уверен, какой тип возвращает criterion),\n",
    "    # предсказания о классе (токсикичный или нет), и настоящий класс (токсичный или нет)),\n",
    "    # а в итоге predict возвращает эти три списка\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "              \n",
    "                input_ids, attention_mask, labels = batch\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].view(-1).to(device)\n",
    "\n",
    "\n",
    "                output = model.forward(input_ids, attention_mask)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "                losses.append(loss.item())\n",
    "                _, predicted = torch.max(output.detach(), 1)\n",
    "                predicted_classes.append(predicted)\n",
    "                true_classes.append(labels)\n",
    "\n",
    "\n",
    "                f1 = f1_score(predicted.cpu().numpy(), labels.cpu().numpy(), zero_division=0)\n",
    "                pbar.set_description('Loss: {:.4f}; F1_score: {:.4f}'.format(loss.item(), f1))    \n",
    "                pbar.update(1)\n",
    "                \n",
    "    predicted_classes = torch.cat(predicted_classes).detach().to('cpu').numpy()\n",
    "    true_classes = torch.cat(true_classes).detach().to('cpu').numpy()\n",
    "    return losses, predicted_classes, true_classes\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=5, scheduler=None):\n",
    "    model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Learning rate: ', optimizer.param_groups[0]['lr'])\n",
    "        print('Epoch:', epoch)\n",
    "        train_one_epoch(model, train_dataloader, criterion, optimizer)\n",
    "        print('Validation')\n",
    "        losses, predicted_classes, true_classes = predict(model, val_dataloader, criterion)\n",
    "        print('F1_score: ', f1_score(true_classes, predicted_classes, zero_division=0))\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0780; F1_score: 1.0000: 100%|█████| 1508/1508 [3:51:23<00:00,  9.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0528; F1_score: 0.0000: 100%|█████| 2494/2494 [1:46:24<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7542306178669815\n",
      "Learning rate:  1e-05\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0566; F1_score: 1.0000: 100%|█████| 1508/1508 [3:34:48<00:00,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0213; F1_score: 0.0000: 100%|█████| 2494/2494 [1:46:12<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7081003066931264\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2581; F1_score: 0.9231: 100%|█████| 1508/1508 [3:33:05<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0042; F1_score: 0.0000: 100%|█████| 2494/2494 [1:45:34<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.73649226094388\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1120; F1_score: 0.9412: 100%|█████| 1508/1508 [3:39:21<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0038; F1_score: 0.0000: 100%|█████| 2494/2494 [1:47:10<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.7287563308947664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pdb.set_trace()\n",
    "train(bert_model, bert_train_dataloader, bert_eval_dataloader, criterion, bert_optimizer, device, n_epochs, bert_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда я первый раз пробовал делать эмбеддингы, ядро умерло после где-то 12 часов обработки. Чтобы избегать повторений такого случая, я разбил данные на 4 части (в конце концов решил соединить части 3 и 4).\n",
    "\n",
    "Из-за этого процесса и размера батчов, я потерял 50 строк данных (то есть, 8112 строк части 1 стал эмбеддингом 8100 строк, и так далее). Из-за огромного количество времени, которое ушло на создание эмбеддингов, я не стал исправить это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth = len(comments)/4\n",
    "\n",
    "print(fourth, fourth*2, fourth*3, fourth*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = tensor_data(comments[0:8112])\n",
    "data_2 = tensor_data(comments[8112:16225])\n",
    "data_3_4 = tensor_data(comments[16225:])\n",
    "# data_4 = tensor_data(comments[24338:])\n",
    "\n",
    "print(len(data_1)+len(data_2)+len(data_3_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_embed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_embed:\n",
    "    batch_size = 100\n",
    "    embeddings_1 = []\n",
    "\n",
    "#     for i in tqdm(range(len(data_1)//batch_size)):\n",
    "#         batch = data_1[batch_size*i:batch_size*(i+1)][0]\n",
    "#         mask = data_1[batch_size*i:batch_size*(i+1)][1]\n",
    "#         with torch.no_grad():\n",
    "#             batch_embeddings = model(batch, attention_mask=mask)\n",
    "#         embeddings_1.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "#     np.savez(\"datasets/batch_embeddings_1\", *embeddings_1)\n",
    "    \n",
    "\n",
    "else:\n",
    "    file_load_1 = np.load(\"datasets/batch_embeddings_1_done.npz\", allow_pickle=True)\n",
    "    embeddings_1 = [file_load_1[n] for n in file_load_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_embed:\n",
    "    batch_size = 100\n",
    "    embeddings_2 = []\n",
    "\n",
    "#     for i in tqdm(range(len(data_2)//batch_size)):\n",
    "#         batch = data_2[batch_size*i:batch_size*(i+1)][0]\n",
    "#         mask = data_2[batch_size*i:batch_size*(i+1)][1]\n",
    "#         with torch.no_grad():\n",
    "#             batch_embeddings = model(batch, attention_mask=mask)\n",
    "#         embeddings_2.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "#     np.savez(\"datasets/batch_embeddings_2\", *embeddings_2)\n",
    "    \n",
    "\n",
    "else:\n",
    "    file_load_2 = np.load(\"datasets/batch_embeddings_2_done.npz\", allow_pickle=True)\n",
    "    embeddings_2 = [file_load_2[n] for n in file_load_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_embed:\n",
    "    batch_size = 100\n",
    "    embeddings_3_4 = []\n",
    "\n",
    "#     for i in tqdm(range(len(data_3_4)//batch_size)):\n",
    "#         batch = data_3_4[batch_size*i:batch_size*(i+1)][0]\n",
    "#         mask = data_3_4[batch_size*i:batch_size*(i+1)][1]\n",
    "#         with torch.no_grad():\n",
    "#             batch_embeddings = model(batch, attention_mask=mask)\n",
    "#         embeddings_3_4.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "#     np.savez(\"datasets/batch_embeddings_3_4\", *embeddings_3_4)\n",
    "    \n",
    "\n",
    "else:\n",
    "    file_load_3_4 = np.load(\"datasets/batch_embeddings_3_4_done.npz\", allow_pickle=True)\n",
    "    embeddings_3_4 = [file_load_3_4[n] for n in file_load_3_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = np.concatenate(embeddings_1)\n",
    "target_1 = comments['toxic'][0:8100]\n",
    "\n",
    "features_2 = np.concatenate(embeddings_2)\n",
    "target_2 = comments['toxic'][8112:16212]\n",
    "\n",
    "features_3_4 = np.concatenate(embeddings_3_4)\n",
    "target_3_4 = comments['toxic'][16225:32425]\n",
    "\n",
    "assert (len(features_1) == len(target_1)) & (len(features_2) == len(target_2)) & (len(features_3_4) == len(target_3_4))\n",
    "\n",
    "features = np.concatenate((features_1, features_2, features_3_4))\n",
    "target = pd.concat((target_1, target_2, target_3_4))\n",
    "\n",
    "assert len(features) == len(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "train_target = np.array(train_target)\n",
    "test_target = np.array(test_target)\n",
    "\n",
    "assert (len(train_features) == len(train_target)) & (len(test_features) == len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Размер тренирочной выборки: {len(train_target)}')\n",
    "print(f'Размер тестовой выборки: {len(test_target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка sklearn моделей\n",
    "\n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=12345)\n",
    "dec_tree = DecisionTreeClassifier(random_state=12345)\n",
    "rand_for = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "model_list = [log_reg, dec_tree, rand_for]\n",
    "model_names = ['logistic_regression', 'decision_tree', 'random_forest']\n",
    "\n",
    "def sklearn_test(train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    f1_results = {}\n",
    "    \n",
    "    for model, name in zip(model_list, model_names):\n",
    "        model.fit(train_features, train_target)\n",
    "        pred = model.predict(test_features)\n",
    "        f1_results[f'{name}'] = list(cross_val_score(model, test_features, test_target, scoring='f1'))\n",
    "        \n",
    "    f1_df = pd.DataFrame.from_dict(f1_results, orient='index')\n",
    "    f1_df.columns = ['cross_val_1', 'cross_val_2', 'cross_val_3', 'cross_val_4', 'cross_val_5']\n",
    "    f1_df['f1_average'] = f1_df.apply(lambda x: sum(x)/len(x), axis=1)\n",
    "    f1_df = f1_df.sort_values('f1_average', ascending=False)\n",
    "    display(f1_df)\n",
    "    \n",
    "\n",
    "sklearn_test(train_features, train_target, test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=12345)\n",
    "dec_tree = DecisionTreeClassifier(random_state=12345)\n",
    "rand_for = RandomForestClassifier(random_state=12345)\n",
    "dummy = DummyClassifier()\n",
    "\n",
    "model_list = [log_reg, dec_tree, rand_for, dummy]\n",
    "model_names = ['logistic_regression', 'decision_tree', 'random_forest', 'dummy']\n",
    "\n",
    "def sklearn_test(train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    f1_results = {}\n",
    "        \n",
    "    for model, name in zip(model_list, model_names):\n",
    "        model.fit(train_features, train_target)\n",
    "        pred = model.predict(test_features)\n",
    "        f1 = f1_score(test_target, pred)\n",
    "        f1_results[f'{name}'] = list(cross_val_score(model, train_features, train_target, scoring='f1'))\n",
    "        f1_results[f'{name}'].append(f1)\n",
    "        \n",
    "        \n",
    "    f1_df = pd.DataFrame.from_dict(f1_results, orient='index')\n",
    "    f1_df.columns = ['cross_val_1', 'cross_val_2', 'cross_val_3', 'cross_val_4', 'cross_val_5', 'test_f1']\n",
    "    f1_df = f1_df.sort_values('test_f1', ascending=False)\n",
    "    display(f1_df)\n",
    "    \n",
    "\n",
    "sklearn_test(train_features, train_target, test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_class = LGBMClassifier()\n",
    "xgb_class = XGBClassifier()\n",
    "cat_class = CatBoostClassifier()\n",
    "model_list = [lgb_class, xgb_class, cat_class]\n",
    "model_names = ['lgb_class', 'xgb_class', 'cat_class']\n",
    "\n",
    "def prelim_test(train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    f1_results = {}\n",
    "    \n",
    "    for model, name in zip(model_list, model_names):\n",
    "        model.fit(train_features, train_target, verbose=False)\n",
    "        pred = model.predict(test_features)\n",
    "        f1 = f1_score(test_target, pred)\n",
    "        f1_results[f'{name}'] = f1\n",
    "        \n",
    "    f1_df = pd.DataFrame.from_dict(f1_results, orient='index')\n",
    "    f1_df.columns = ['f1_score']\n",
    "    f1_df = f1_df.sort_values('f1_score', ascending=False)\n",
    "    display(f1_df)\n",
    "\n",
    "prelim_test(train_features, train_target, test_features, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective_lgb(trial):\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 50, 500, 25),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.05, 0.2),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 1, 20, 2),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 50, 1000, 50),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 300, 10),\n",
    "        'verbose' : -1\n",
    "    }\n",
    "    lgb_mod = LGBMClassifier(**params, random_state=12345)\n",
    "    lgb_mod.fit(train_features, train_target)\n",
    "    pred = lgb_mod.predict(test_features)\n",
    "    f1 = f1_score(test_target, pred)\n",
    "    return f1\n",
    "\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=20)\n",
    "\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study_lgb.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial_lgb = study_lgb.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial_lgb.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial_lgb.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "display(optuna.importance.get_param_importances(study_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of finished trials: 20\n",
    "\n",
    "Best trial:\n",
    "\n",
    "  Value: 0.8901662265030293\n",
    "  \n",
    "  Params: \n",
    "  \n",
    "    n_estimators: 500\n",
    "    learning_rate: 0.15060263548375816\n",
    "    max_depth: 17\n",
    "    reg_alpha: 6.724134652658169e-06\n",
    "    reg_lambda: 7.488943400676552\n",
    "    num_leaves: 200\n",
    "    colsample_bytree: 0.9352407649941042\n",
    "    subsample: 0.8502365864897415\n",
    "    subsample_freq: 2\n",
    "    min_child_samples: 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def objective_xgb(trial):\n",
    "        \n",
    "        params = {\n",
    "         'n_estimators' : trial.suggest_int('n_estimators', 5, 150),\n",
    "         'max_depth' : trial.suggest_int('max_depth', 2, 16),\n",
    "         'max_leaves' : trial.suggest_int('max_leaves', 30, 100),\n",
    "         'learning_rate' : trial.suggest_float('learning_rate', 0.1, 1),\n",
    "         'reg_alpha' : trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "         'reg_lambda' : trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "         'verbosity' : 0,\n",
    "         'booster' : 'gbtree'\n",
    "        }\n",
    "        xgb_class = XGBClassifier(**params, random_state=12345)\n",
    "        xgb_class.fit(train_features, train_target)\n",
    "        pred = xgb_class.predict(test_features)\n",
    "        f1 = f1_score(test_target, pred)\n",
    "        return f1\n",
    "    \n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=20)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study_xgb.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial_xgb = study_xgb.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial_xgb.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial_xgb.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "display(optuna.importance.get_param_importances(study_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of finished trials: 20\n",
    "\n",
    "Best trial:\n",
    "\n",
    "  Value: 0.09294320137693632\n",
    "  \n",
    "  Params: \n",
    "  \n",
    "    n_estimators: 5\n",
    "    max_depth: 13\n",
    "    max_leaves: 76\n",
    "    learning_rate: 0.853680753351705\n",
    "    reg_alpha: 0.02833383057451046\n",
    "    reg_lambda: 0.022508569427159838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier дал хороший изначальный результат, но он очень долго у меня обрабатывается. Я пробовал использовать optuna как в ячейке ниже пару раз, с малым количеством n_trials, но результат был хуже чем с стандартными параметрами. Я уверен, что CatBoostClassifier может дать результат по лучше, но из-за долгого времени обработки я не стал сыскать лучшие параметры чем стандартные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_cat(trial):\n",
    "    \n",
    "#     params = {\n",
    "#         'iterations' : trial.suggest_int('iterations', 10, 100, 10),\n",
    "#         'depth' : trial.suggest_int('depth', 1, 16),\n",
    "#         'learning_rate' : trial.suggest_float('learning_rate', 0.1, 1),\n",
    "#         'subsample' : trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "#         'early_stopping_rounds' : 70,\n",
    "#         'eval_metric' : 'F1',\n",
    "#         'silent' : True\n",
    "#     }\n",
    "    \n",
    "#     cat_mod = CatBoostClassifier(**params, random_state=12345)\n",
    "#     cat_mod.fit(train_features, train_target)\n",
    "#     pred = cat_mod.predict(test_features)\n",
    "#     f1 = f1_score(test_target, pred)\n",
    "#     return f1\n",
    "\n",
    "# study_cat = optuna.create_study(direction='maximize')\n",
    "# study_cat.optimize(objective_cat, n_trials=5)\n",
    "\n",
    "\n",
    "# print(\"Number of finished trials: {}\".format(len(study_cat.trials)))\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial_cat = study_cat.best_trial\n",
    "\n",
    "# print(\"  Value: {}\".format(trial_cat.value))\n",
    "\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial_cat.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "# display(optuna.importance.get_param_importances(study_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучшие модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = {}\n",
    "\n",
    "### CatBoost\n",
    "\n",
    "best_cat = CatBoostClassifier(silent=True, random_state=12345)\n",
    "\n",
    "best_cat.fit(train_features, train_target)\n",
    "pred = best_cat.predict(test_features)\n",
    "\n",
    "f1 = f1_score(test_target, pred)\n",
    "best_f1['CatBoost'] = f1\n",
    "\n",
    "\n",
    "### LGBMClassifier\n",
    "\n",
    "best_params_lgb = {\"boosting_type\" : 'gbdt', \n",
    "                   \"verbosity\" : -1, \n",
    "                   \"n_estimators\" : 500, \n",
    "                   \"learning_rate\" : 0.15060263548375816, \n",
    "                   \"max_depth\" : 17,\n",
    "                   \"reg_alpha\" : 6.724134652658169e-06,\n",
    "                   \"reg_lambda\" : 7.488943400676552,\n",
    "                   \"num_leaves\" : 200,\n",
    "                   \"colsample_bytree\" : 0.9352407649941042,\n",
    "                   \"subsample\" : 0.8502365864897415,\n",
    "                   \"subsample_freq\" : 2,\n",
    "                   \"min_child_samples\" : 180\n",
    "}\n",
    "\n",
    "best_lgb = LGBMClassifier(**best_params_lgb, random_state=12345)\n",
    "\n",
    "best_lgb.fit(train_features, train_target)\n",
    "pred = best_lgb.predict(test_features)\n",
    "\n",
    "f1 = f1_score(test_target, pred,)\n",
    "best_f1['LGBM'] = f1\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "best_params_xgb = {\"verbosity\" : 0,\n",
    "                   \"booster\" : 'gbtree',\n",
    "                   \"n_estimators\" : 5,\n",
    "                   \"max_depth\" : 13,\n",
    "                   \"max_leaves\" : 76,\n",
    "                   \"learning_rate\" : 0.853680753351705,\n",
    "                   \"reg_alpha\" : 0.02833383057451046,\n",
    "                   \"reg_lambda\" : 0.022508569427159838\n",
    "}\n",
    "\n",
    "best_xgb = XGBClassifier(**best_params_xgb, random_state=12345)\n",
    "\n",
    "best_xgb.fit(train_features, train_target)\n",
    "pred = best_xgb.predict(test_features)\n",
    "\n",
    "f1 = f1_score(test_target, pred)\n",
    "best_f1['XGBoost'] = f1\n",
    "\n",
    "\n",
    "best_models_df = pd.DataFrame.from_dict(best_f1, orient=\"index\")\n",
    "best_models_df.columns = ['f1']\n",
    "best_models_df = best_models_df.sort_values(by='f1')\n",
    "display(best_models_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_df = best_models_df.sort_values(by='f1', ascending=False)\n",
    "display(best_models_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT дал очень хороший результат:\n",
    "\n",
    "Лучшая модель: LGBMClassifier\n",
    "\n",
    "F1 score: 0.8875\n",
    "\n",
    "Параметры:\n",
    "\n",
    "    \"boosting_type\" : 'gbdt', \n",
    "    \"verbosity\" : -1, \n",
    "    \"n_estimators\" : 500, \n",
    "    \"learning_rate\" : 0.15060263548375816, \n",
    "    \"max_depth\" : 17,\n",
    "    \"reg_alpha\" : 6.724134652658169e-06,\n",
    "    \"reg_lambda\" : 7.488943400676552,\n",
    "    \"num_leaves\" : 200,\n",
    "    \"colsample_bytree\" : 0.9352407649941042,\n",
    "    \"subsample\" : 0.8502365864897415,\n",
    "    \"subsample_freq\" : 2,\n",
    "    \"min_child_samples\" : 180\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
